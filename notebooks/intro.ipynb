{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e31860-7a95-4ffe-93a8-9234491be5ef",
   "metadata": {},
   "source": [
    "# Langchain basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed757db-20dc-4634-a4b5-1c44bcadb91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a267b31-9167-40ff-990d-33cbd0b6f456",
   "metadata": {},
   "source": [
    "## Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d7dbf8-5e54-4f96-9e19-7616e945331c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965591d-081f-4f87-9122-43d3b54547ac",
   "metadata": {},
   "source": [
    "### LLM Models(Wrappers): GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17561a4-74bc-47cb-b1ab-f829b81940e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 512, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7226b51-5e47-4b6f-ab0b-d43303247611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantum mechanics is the physical theory describing the behavior and interaction of matter and energy at the atomic and subatomic level.\n"
     ]
    }
   ],
   "source": [
    "output = llm('explain quantum mechanics in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddda7c5d-8556-4934-8960-2c1b154d9b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens(\"explain quantum mechanics in one sentence\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489b91be-737c-4728-8a41-ece9c830454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output =  llm.generate([\"... is the capital of France.\", \"What is the formula for the area of circle?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62c1fb12-778a-4418-90f7-8f6312bf9b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\n\\nParis', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe formula for the area of a circle is A = πr², where r is the radius of the circle and π is the mathematical constant approximately equal to 3.14.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e02f724-8cbc-4cb6-9599-10d6494cf1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The formula for the area of a circle is A = πr², where r is the radius of the circle and π is the mathematical constant approximately equal to 3.14.\n"
     ]
    }
   ],
   "source": [
    "# Only one answer - 2nd question\n",
    "print(output.generations[1][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad61409-aec9-4c9d-96da-0f01bf771092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paris\n"
     ]
    }
   ],
   "source": [
    "# Only one answer - 1st question\n",
    "print(output.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69453b6d-7d81-41fa-8233-0b45d4c62000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of generations\n",
    "len(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae422743-15c6-4534-8193-c59347597826",
   "metadata": {},
   "outputs": [],
   "source": [
    "output =  llm.generate([\"Write an original taglines for burger restaurant\"] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf698743-3382-4279-9780-5db7594f25d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[Generation(text='\\n\\n\"Taste the Difference at Our Burger Joint - Satisfaction Guaranteed!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\n\"A Bite Above the Rest - Burgers with a Delicious Twist!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\n\"Taste the Juiciness of our Burgers - Satisfaction Guaranteed!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})]] llm_output={'token_usage': {'prompt_tokens': 24, 'completion_tokens': 52, 'total_tokens': 76}, 'model_name': 'text-davinci-003'} run=[RunInfo(run_id=UUID('1e75d04e-0c17-4a0e-bf53-c04cadcdaabe')), RunInfo(run_id=UUID('4c179036-880f-4e82-8538-ae13411ee095')), RunInfo(run_id=UUID('5a6c3b6e-9758-4dfa-9be5-bde3daaeaa75'))]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "054711fd-0729-4866-818e-07c6f3feb284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Taste the Difference at Our Burger Joint - Satisfaction Guaranteed!\"\n",
      "\n",
      "\n",
      "\"A Bite Above the Rest - Burgers with a Delicious Twist!\"\n",
      "\n",
      "\n",
      "\"Taste the Juiciness of our Burgers - Satisfaction Guaranteed!\"\n"
     ]
    }
   ],
   "source": [
    "for i in output.generations:\n",
    "    print(i[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175bd80-d024-47ee-ba8e-576469f01009",
   "metadata": {},
   "source": [
    "## ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6fa9a6f-e733-40a9-b6c8-a7e41301d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import schema for the structure called messages\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a3b5bd9-30b9-41d7-8511-5ae6c9823407",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a physicist and respond only in German.\"),\n",
    "    HumanMessage(content=\"Explain quantum mechanics in one sentence\")\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c12f10da-18b4-4515-8089-9d734ff581bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Quantenmechanik beschreibt das Verhalten von Teilchen auf sehr kleinen Skalen und ermöglicht Vorhersagen über Wahrscheinlichkeiten von Ereignissen.'\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "648956ac-4803-441a-ad60-8c0e0e102123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantenmechanik beschreibt das Verhalten von Teilchen auf sehr kleinen Skalen und ermöglicht Vorhersagen über Wahrscheinlichkeiten von Ereignissen.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a8ce85-665c-492e-8b1a-2e2c3503e69d",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "creates dynamic prompts for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5cd99ef-ecbf-47ef-9fd1-e1f1181399ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cff5cbf-adab-4125-9452-666dc66bf8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['language', 'virus'] template='You are an experienced virologist.\\nWrite a few sentences about the following {virus} in {language}'\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"virus\", \"language\"],\n",
    "    template = template\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2311c4a5-21e4-4b7d-991f-23066375279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n",
      "L'Ebola est une maladie virale très grave qui se propage par contact direct avec des liquides corporels infectés. Les symptômes comprennent la fièvre, la fatigue, des maux de tête et des douleurs musculaires, des vomissements et de la diarrhée, et peuvent évoluer vers une insuffisance des organes vitaux. La prise en charge et le traitement adéquats sont essentiels pour lutter contre la maladie et sauver des vies.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0.7)\n",
    "output = llm(prompt.format(virus='ebola', language='french'))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30866cd5-fffe-461c-9163-8b7e8573a8e7",
   "metadata": {},
   "source": [
    "## Simple Chains\n",
    "Chains allow us to combine multiple components together to create a simple application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c5ab050-e6bb-4df4-84cb-27c3b0f41ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "template = \"\"\"You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"virus\", \"language\"],\n",
    "    template = template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run({'virus': \"HSV\", 'language': 'french'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f712ac9-f2e9-4f3d-90c1-7e68d6c22c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le HSV, également connu sous le nom de virus de l'herpès simplex, est un virus à ADN double brin de la famille des Herpesviridae. Il existe deux types d'HSV : le HSV-1, qui provoque généralement des infections buccales et labiales, et le HSV-2, qui est principalement responsable des infections génitales. Ces virus sont hautement contagieux et se transmettent principalement par contact direct avec les lésions cutanées ou les muqueuses infectées. Les symptômes courants incluent des lésions vésiculaires douloureuses, des démangeaisons et des brûlures. Bien qu'il n'existe pas de traitement curatif pour le HSV, des médicaments antiviraux peuvent aider à réduire la fréquence et la gravité des récidives.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6975deb3-c1bc-44c7-b108-6f3c9b74e83a",
   "metadata": {},
   "source": [
    "## Sequential Chains\n",
    "Make a series of calls to one or more LLMs. You can take the output from the chain and use it as input to another chain.\n",
    "There are 2 types of sequential chains:\n",
    "1. SimpleSequential Chains\n",
    "2. General form of Sequential chains\n",
    "\n",
    "Simple sequential chains represent a series of chains, where each individual chain has a single input and a single output, and the output of one step is used as input to the next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4000c529-0e5a-4d36-9ca0-3ee26b35aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m.\n",
      "\n",
      "def linear_regression(x, y):\n",
      "    \"\"\"\n",
      "    Implements the concept of linear regression.\n",
      "    \n",
      "    Parameters:\n",
      "    x (list): x-values of the data points\n",
      "    y (list): y-values of the data points\n",
      "    \n",
      "    Returns:\n",
      "    slope (float): the slope of the best-fit line\n",
      "    intercept (float): the intercept of the best-fit line\n",
      "    \"\"\"\n",
      "    # Calculate the mean values of x and y\n",
      "    x_mean = sum(x)/len(x)\n",
      "    y_mean = sum(y)/len(y)\n",
      "    \n",
      "    # Calculate the numerator and denominator of the slope\n",
      "    numerator = 0\n",
      "    denominator = 0\n",
      "    for i in range(len(x)):\n",
      "        numerator += (x[i] - x_mean) * (y[i] - y_mean)\n",
      "        denominator += (x[i] - x_mean)**2\n",
      "    \n",
      "    # Calculate the slope and intercept\n",
      "    slope = numerator/denominator\n",
      "    intercept = y_mean - slope * x_mean\n",
      "    \n",
      "    return slope, intercept\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "\n",
      "This function implements the concept of linear regression, which is a method to determine the relationship between two variables. It takes two lists of values (x and y) and calculates the slope and intercept of the best-fit line that describes the data points. The function first calculates the mean values of the x and y lists. It then calculates the numerator and denominator of the slope by looping through the x and y lists. Finally, it calculates the slope and intercept using the mean values and the numerator and denominator. The function then returns the calculated slope and intercept.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables = [\"concept\"],\n",
    "    template = \"\"\"You are an experienced scientist and python developer.\n",
    "    Write a function that implements the concept of {concept}\"\"\"\n",
    ")\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables = [\"function\"],\n",
    "    template = \"\"\"Given the python function {function}, describe it as detailed as possible\"\"\"\n",
    ")\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose= True)\n",
    "output = overall_chain.run('linear_regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8f5fc-d5b1-4780-8fcc-e20d001fe632",
   "metadata": {},
   "source": [
    "## LangChain Agents\n",
    "Agents are enabling tools for LLMs, then they can do calculations, write code, search the webs or run SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19861ce9-c7ca-455f-b480-100817211249",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f328adbc-26b9-402e-bc19-0377af37325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f275e92e-e61b-4ffa-b939-17b5646e0df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to calculate the factorial of 20 and then take the square root of that\n",
      "Action: Python_REPL\n",
      "Action Input: from math import factorial; print(round(factorial(20)**0.5, 4))\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1559776268.6285\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 1559776268.6285\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1559776268.6285'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "# Tools are essentially functions agents can use to interact with outside world.\n",
    "# It can range from genrtal utilities such as maths calculator, search functions to other chains or other agents\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(), #Tools\n",
    "    verbose=True)\n",
    "agent_executor.run('Calculate the square root of the factorial of 20 and display it with 4 decimal points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068bc169-6dea-4e64-bb37-a9c9487f238d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
